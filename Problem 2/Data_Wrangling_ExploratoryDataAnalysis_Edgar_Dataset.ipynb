{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import logging\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import boto\n",
    "from boto.s3.connection import Location\n",
    "from boto.s3.key import Key\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a log file 'problem2_log.log'\n",
    "\n",
    "root = logging.getLogger()\n",
    "root.setLevel(logging.DEBUG)\n",
    "ch1 = logging.FileHandler('problem2_log.log')\n",
    "ch1.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "ch1.setFormatter(formatter)\n",
    "root.addHandler(ch1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please input the S3 Access Key\n",
      "AKIAJXHKVBG5ZPESTMLQ\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#input the parameters\n",
    "\n",
    "print (\"Please input the S3 Access Key\")\n",
    "accessKey = input()\n",
    "logging.info(\"Access Key = %s\" % accessKey)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please input the S3 Secret Access Key\n",
      "rYA1AlHu5gdS7qlW4SjXcvhhHjZRrOhfQaX1fw1z\n"
     ]
    }
   ],
   "source": [
    "print (\"Please input the S3 Secret Access Key\")\n",
    "secretAccessKey = input()\n",
    "logging.info(\"Secret Access Key = %s\" % secretAccessKey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please input your location\n",
      "us-east\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print (\"Please input your location\")\n",
    "location = input()\n",
    "if location not in ['APNortheast', 'APSoutheast', 'APSoutheast2', 'EU', 'EUCentral1', 'SAEast', 'USWest', 'USWest2']:\n",
    "    location = 'Default'\n",
    "logging.info(\"Location = %s\" % location)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please input the Year\n",
      "2010\n"
     ]
    }
   ],
   "source": [
    "year_range = range(2003, 2018)\n",
    "\n",
    "print (\"Please input the Year\")\n",
    "year = input()\n",
    "if int(year) not in year_range:\n",
    "    logging.error(\"Invalid year. Please enter a valid year between 2003 and 2017.\")\n",
    "    exit()\n",
    "logging.info(\"Year = %s\", year)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verifying the AWS account\n",
    "\n",
    "AWS_ACCESS_KEY_ID = accessKey\n",
    "AWS_SECRET_ACCESS_KEY = secretAccessKey\n",
    "\n",
    "try:\n",
    "    s3_connection = boto.connect_s3(AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY)\n",
    "    region = s3_connection.get_all_regions()\n",
    "    print ('connected to S3!')\n",
    "\n",
    "except:\n",
    "    logging.info(\"Amazon keys are invalid!\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Directory CLeansing  \n",
    "\n",
    "zip_dir = year + '_zips'\n",
    "unzipped_dir = year + '_unzipped'\n",
    "try:\n",
    "    if not os.path.exists(zip_dir):\n",
    "        os.makedirs(zip_dir, mode=0o777)\n",
    "    else:\n",
    "        shutil.rmtree(os.path.join(os.path.dirname(__file__), zip_dir), ignore_errors=False)\n",
    "        os.makedirs(zip_dir, mode=0o777)\n",
    "\n",
    "    if not os.path.exists(unzipped_dir):\n",
    "        os.makedirs(unzipped_dir, mode=0o777)\n",
    "    else:\n",
    "        shutil.rmtree(os.path.join(os.path.dirname(__file__), unzipped_dir), ignore_errors=False)\n",
    "        os.makedirs(unzipped_dir, mode=0o777)\n",
    "    logging.info('Directories cleanup completed.')\n",
    "except Exception as e:\n",
    "    logging.error(str(e))\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generation of URLs\n",
    "domain = \"http://www.sec.gov/dera/data/Public-EDGAR-log-file-data/\"\n",
    "urls = []\n",
    "year_range = range(2003, 2017)\n",
    "month_quarter = {'Qtr1': ['01', '02', '03'], 'Qtr2': ['04', '05', '06'],\n",
    "                 'Qtr3': ['07', '08', '09'], 'Qtr4': ['10', '11', '12']}\n",
    "\n",
    "for key, value in month_quarter.items():\n",
    "    for v in value:\n",
    "        url = domain + str(year) + '/' + str(key) + '/' + 'log' + str(year) + str(v) + '01.zip'\n",
    "        logging.info('url to download zip %s', url)\n",
    "        urls.append(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Download the 12 zip files from the URLs\n",
    "\n",
    "try:\n",
    "    for i in range(0, 12):\n",
    "        month_zip_dir = zip_dir + '/' + str(i) + '.zip'\n",
    "        month_unzipped_dir = unzipped_dir + '/' + str(i)\n",
    "        r = requests.get(urls[i],allow_redirects=True)\n",
    "        open(month_zip_dir, 'wb').write(r.content)\n",
    "        if os.path.getsize(month_zip_dir) <= 4515: #catching empty file\n",
    "            os.remove(month_zip_dir)\n",
    "            logging.warning('Log file %s is empty.', i)\n",
    "        else:\n",
    "            logging.info('Log file %s successfully downloaded', i)\n",
    "            try:\n",
    "                zip_ref = zipfile.ZipFile(month_zip_dir, 'r')\n",
    "                for file in zip_ref.namelist():\n",
    "                    if file.endswith('.csv'):\n",
    "                        zip_ref.extract(file, unzipped_dir)\n",
    "                        zip_ref.close()\n",
    "                        logging.info('Log file %s was successfully unzipped', i)\n",
    "            except Exception as e:\n",
    "                logging.error(str(e))\n",
    "                exit()\n",
    "except Exception as e:  # Catching file not found\n",
    "    logging.warning('Log %s not found...Skipping ahead!', i)\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_lists = glob.glob(unzipped_dir + \"/*.csv\")\n",
    "\n",
    "all_csv_df_dict = {period: pd.read_csv(period) for period in file_lists}\n",
    "logging.info('All the csv read into individual dataframes')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    for k, v in all_csv_df_dict.items():\n",
    "        st = all_csv_df_dict[k]\n",
    "        for key, value in st.items():\n",
    "            key_drop = {'cik', 'accession', 'ip', 'date', 'time'}\n",
    "            key_max = {'idx', 'browser', 'code', 'find', 'extention', 'zone'}\n",
    "            df = pd.DataFrame(st[key])\n",
    "            null_count = df.isnull().sum()\n",
    "            logging.info(\"count of null in  %s is %s\" % (key, null_count))\n",
    "            most_used_value = pd.DataFrame(df.groupby(key).size().rename('cnt')).idxmax()[0]\n",
    "            if key == \"idx\":\n",
    "                incorrect_idx = (~df.isin([0.0, 1.0])).sum()\n",
    "                logging.info(\"count of incorrect idx is %s\" % incorrect_idx)\n",
    "                st[key] = st[key].fillna(most_used_value)\n",
    "                logging.info(\"fill the null value in column %s with the most used value\" % key)\n",
    "            elif key == \"norefer\":\n",
    "                incorrect_norefer = (~df.isin([0.0, 1.0])).sum()\n",
    "                logging.info(\"count of incorrect norefer is %s\" % incorrect_norefer)\n",
    "                st[key] = st[key].fillna('1')\n",
    "                logging.info(\"fill the null value in column %s with 1\" % key)\n",
    "            elif key == \"noagent\":\n",
    "                incorrect_noagent = (~df.isin([0.0, 1.0])).sum()\n",
    "                logging.info(\"count of incorrect noagent is %s\" % incorrect_noagent)\n",
    "                st[key] = st[key].fillna('1')\n",
    "                logging.info( \"fill the null value in column %s with 1\" % key)\n",
    "            elif key in key_drop:\n",
    "                st[key] = st.dropna(subset=[key])\n",
    "                logging.info(\"the null in %s is dropped\" % key)\n",
    "            elif key in key_max:\n",
    "                st[key] = st[key].fillna(most_used_value)\n",
    "                logging.info(\"fill the null value in column %s with the most used value\" % key)\n",
    "            elif key == \"crawler\":\n",
    "                st[key] = st[key].fillna('0')\n",
    "                logging.info(\"fill the null value in column %s with 0\" % key)\n",
    "            elif key == \"size\":\n",
    "                st[key] = st[key].fillna(st[key].mean(axis=0))\n",
    "                logging.info(\"fill the null value in column %s with the average value\" % key)\n",
    "except Exception as e:\n",
    "    logging.error(str(e))\n",
    "    exit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#zip the csv and log\n",
    "\n",
    "try:\n",
    "    dfs = pd.concat(all_csv_df_dict)\n",
    "    dfs.to_csv('login_data.csv')\n",
    "    logging.info('All dataframes of csvs are combined and exported as csv: master_csv.csv.')\n",
    "except Exception as e:\n",
    "    logging.error(str(e))\n",
    "    exit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zipdir(path, ziph):\n",
    "    ziph.write(os.path.join('login_data.csv'))\n",
    "    ziph.write(os.path.join('problem2_log.log'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipf = zipfile.ZipFile('Problem2.zip', 'w', zipfile.ZIP_DEFLATED)\n",
    "zipdir('/', zipf)\n",
    "zipf.close()\n",
    "logging.info(\"csv and log files successfully zipped!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Upload the zip file to Amazon S3 Bucket\n",
    "\n",
    "try:\n",
    "    zipfile = 'Problem2.zip'\n",
    "    ts = time.time()\n",
    "    st = datetime.datetime.fromtimestamp(ts)\n",
    "    bucket_name = AWS_ACCESS_KEY_ID.lower() + str(st).replace(\" \", \"\").replace(\"-\", \"\").replace(\":\", \"\").replace(\".\", \"\")\n",
    "    conn = boto.connect_s3(AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY)\n",
    "    bucket = conn.create_bucket(bucket_name, location=location)\n",
    "    print ('bucket created')\n",
    "    print \"Uploading %s to Amazon S3 bucket %s\" % (zipfile, bucket_name)\n",
    "\n",
    "    k = Key(bucket)\n",
    "    k.key = 'Problem2'\n",
    "    k.set_contents_from_filename(zipfile)\n",
    "    print(\"Zip File successfully uploaded to S3\")\n",
    "except:\n",
    "    logging.info(\"AWS credentials are invalid!\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
